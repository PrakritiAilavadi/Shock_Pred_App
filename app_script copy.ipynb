{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## App script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting image\n",
      "  Downloading https://files.pythonhosted.org/packages/0c/ec/51969468a8b87f631cc0e60a6bf1e5f6eec8ef3fd2ee45dc760d5a93b82a/image-1.5.27-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pillow in /anaconda3/envs/tav_lab/lib/python3.6/site-packages (from image) (6.1.0)\n",
      "Collecting django (from image)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/57/66997ca6ef17d2d0f0ebcd860bc6778095ffee04077ca8985928175da358/Django-2.2.4-py3-none-any.whl (7.5MB)\n",
      "\u001b[K     |████████████████████████████████| 7.5MB 2.0MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz in /anaconda3/envs/tav_lab/lib/python3.6/site-packages (from django->image) (2019.1)\n",
      "Collecting sqlparse (from django->image)\n",
      "  Using cached https://files.pythonhosted.org/packages/ef/53/900f7d2a54557c6a37886585a91336520e5539e3ae2423ff1102daf4f3a7/sqlparse-0.3.0-py2.py3-none-any.whl\n",
      "Installing collected packages: sqlparse, django, image\n",
      "Successfully installed django-2.2.4 image-1.5.27 sqlparse-0.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Keras\n",
      "  Using cached https://files.pythonhosted.org/packages/f8/ba/2d058dcf1b85b9c212cc58264c98a4a7dd92c989b798823cc5690d062bb2/Keras-2.2.5-py2.py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.9.1 in /anaconda3/envs/tav_lab/lib/python3.6/site-packages (from Keras) (1.16.4)\n",
      "Collecting keras-preprocessing>=1.1.0 (from Keras)\n",
      "  Using cached https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl\n",
      "Collecting pyyaml (from Keras)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/e8/b3212641ee2718d556df0f23f78de8303f068fe29cdaa7a91018849582fe/PyYAML-5.1.2.tar.gz (265kB)\n",
      "\u001b[K     |████████████████████████████████| 266kB 210kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting h5py (from Keras)\n",
      "  Using cached https://files.pythonhosted.org/packages/03/21/1cdf7fa7868528b35c1a08a770eb9334279574a8b5f1d7a2966dcec14e42/h5py-2.9.0-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n",
      "Collecting keras-applications>=1.0.8 (from Keras)\n",
      "  Using cached https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl\n",
      "Requirement already satisfied: scipy>=0.14 in /anaconda3/envs/tav_lab/lib/python3.6/site-packages (from Keras) (1.3.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /anaconda3/envs/tav_lab/lib/python3.6/site-packages (from Keras) (1.12.0)\n",
      "Building wheels for collected packages: pyyaml\n",
      "  Building wheel for pyyaml (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/prakritiailavadi/Library/Caches/pip/wheels/d9/45/dd/65f0b38450c47cf7e5312883deb97d065e030c5cca0a365030\n",
      "Successfully built pyyaml\n",
      "Installing collected packages: keras-preprocessing, pyyaml, h5py, keras-applications, Keras\n",
      "Successfully installed Keras-2.2.5 h5py-2.9.0 keras-applications-1.0.8 keras-preprocessing-1.1.0 pyyaml-5.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/8c/7608ba709bd536bc2bccb0d1abbb70aafe9cf7e0170353b4b720ed54cb71/tensorflow-1.14.0-cp36-cp36m-macosx_10_11_x86_64.whl (105.8MB)\n",
      "\u001b[K     |████████████████████████████████| 105.8MB 104kB/s eta 0:00:01   |█▏                              | 3.9MB 4.1MB/s eta 0:00:26     |██████▏                         | 20.5MB 255kB/s eta 0:05:34     |████████▍                       | 27.9MB 298kB/s eta 0:04:22     |█████████▎                      | 30.6MB 277kB/s eta 0:04:32     |█████████████▋                  | 45.0MB 285kB/s eta 0:03:33     |███████████████▏                | 50.3MB 863kB/s eta 0:01:05     |███████████████████▋            | 64.7MB 1.2MB/s eta 0:00:34     |███████████████████████▊        | 78.5MB 626kB/s eta 0:00:44     |█████████████████████████▏      | 83.2MB 456kB/s eta 0:00:50\n",
      "\u001b[?25hCollecting google-pasta>=0.1.6 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/d0/33/376510eb8d6246f3c30545f416b2263eee461e40940c2a4413c711bdf62d/google_pasta-0.1.7-py3-none-any.whl\n",
      "Collecting grpcio>=1.8.6 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/7f/a1/cb18aa345c9d5272377f04be871f86b973d9db41937a3c558f4eb16ae924/grpcio-1.23.0-cp36-cp36m-macosx_10_9_x86_64.whl\n",
      "Collecting tensorboard<1.15.0,>=1.14.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl\n",
      "Requirement already satisfied: six>=1.10.0 in /anaconda3/envs/tav_lab/lib/python3.6/site-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /anaconda3/envs/tav_lab/lib/python3.6/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /anaconda3/envs/tav_lab/lib/python3.6/site-packages (from tensorflow) (0.33.4)\n",
      "Collecting astor>=0.6.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/d1/4f/950dfae467b384fc96bc6469de25d832534f6b4441033c39f914efd13418/astor-0.8.0-py2.py3-none-any.whl\n",
      "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl\n",
      "Collecting protobuf>=3.6.1 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/b5/24/d910231174d60c16b3b45db520d21581464049b28ba3562ecd5705c5d5c0/protobuf-3.9.1-cp36-cp36m-macosx_10_9_intel.whl\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /anaconda3/envs/tav_lab/lib/python3.6/site-packages (from tensorflow) (1.16.4)\n",
      "Collecting absl-py>=0.7.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/da/3f/9b0355080b81b15ba6a9ffcf1f5ea39e307a2778b2f2dc8694724e8abd5b/absl-py-0.7.1.tar.gz\n",
      "Collecting wrapt>=1.11.1 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/23/84/323c2415280bc4fc880ac5050dddfb3c8062c2552b34c2e512eb4aa68f79/wrapt-1.11.2.tar.gz\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Collecting gast>=0.2.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /anaconda3/envs/tav_lab/lib/python3.6/site-packages (from tensorflow) (1.0.8)\n",
      "Collecting werkzeug>=0.11.15 (from tensorboard<1.15.0,>=1.14.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/d1/ab/d3bed6b92042622d24decc7aadc8877badf18aeca1571045840ad4956d3f/Werkzeug-0.15.5-py2.py3-none-any.whl\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /anaconda3/envs/tav_lab/lib/python3.6/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (41.0.1)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<1.15.0,>=1.14.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: h5py in /anaconda3/envs/tav_lab/lib/python3.6/site-packages (from keras-applications>=1.0.6->tensorflow) (2.9.0)\n",
      "Building wheels for collected packages: absl-py, wrapt, termcolor, gast\n",
      "  Building wheel for absl-py (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/prakritiailavadi/Library/Caches/pip/wheels/ee/98/38/46cbcc5a93cfea5492d19c38562691ddb23b940176c14f7b48\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/prakritiailavadi/Library/Caches/pip/wheels/d7/de/2e/efa132238792efb6459a96e85916ef8597fcb3d2ae51590dfd\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/prakritiailavadi/Library/Caches/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "  Building wheel for gast (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/prakritiailavadi/Library/Caches/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
      "Successfully built absl-py wrapt termcolor gast\n",
      "Installing collected packages: google-pasta, grpcio, werkzeug, markdown, absl-py, protobuf, tensorboard, astor, tensorflow-estimator, wrapt, termcolor, gast, tensorflow\n",
      "Successfully installed absl-py-0.7.1 astor-0.8.0 gast-0.2.2 google-pasta-0.1.7 grpcio-1.23.0 markdown-3.1.1 protobuf-3.9.1 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0 termcolor-1.1.0 werkzeug-0.15.5 wrapt-1.11.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/Users/prakritiailavadi/Desktop/post_grad/project2/shock App/p000020_264490_Abnormal_1_41_1201.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['X.HR.','X.RESP.','X.SpO2.','final_abp_sys','final_abp_dias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr = np.array(data[[cols[0]]]).reshape(-1,256)\n",
    "rr = np.array(data[[cols[1]]]).reshape(-1,256)\n",
    "spo = np.array(data[[cols[2]]]).reshape(-1,256)\n",
    "sys = np.array(data[[cols[3]]]).reshape(-1,256)\n",
    "dia = np.array(data[[cols[4]]]).reshape(-1,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. , 79.9, 80. , 80. ,\n",
       "        80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. ,\n",
       "        80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. ,\n",
       "        80. , 80. , 80. , 80. , 79.2, 78.9, 80. , 80. , 80. , 80. , 80. ,\n",
       "        80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. ,\n",
       "        80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. ,\n",
       "        80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. ,\n",
       "        80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. ,\n",
       "        80. , 80. , 80. , 80. , 80. , 79.8, 80. , 80. , 80. , 80. , 80. ,\n",
       "        80.1, 80. , 80. , 80. , 77.4, 80.2, 77.4, 77.1, 74.8, 78.9, 79.9,\n",
       "        80. , 80. , 80. , 80. , 80. , 80. , 79.9, 80. , 80. , 79.9, 80. ,\n",
       "        80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. ,\n",
       "        80. , 80. , 80. , 79.9, 80. , 80.5, 80. , 80. , 80. , 80. , 80. ,\n",
       "        80. , 80. , 80.7, 80.3, 80. , 80. , 80. , 80. , 80. , 80. , 79.9,\n",
       "        80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. ,\n",
       "        79.9, 80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. ,\n",
       "        80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. , 80.3,\n",
       "        80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. ,\n",
       "        80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. ,\n",
       "        80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. ,\n",
       "        80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. ,\n",
       "        80. , 80. , 80. , 80. , 80. , 80. , 81. , 80. , 80. , 80. , 80. ,\n",
       "        80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. , 80. ,\n",
       "        80. , 80. , 80. ]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dia_snake = np.zeros((dia.shape[0], 256), dtype = np.float32)\n",
    "X_hr_snake = np.zeros((hr.shape[0], 256), dtype = np.float32)\n",
    "X_rr_snake = np.zeros((rr.shape[0], 256), dtype = np.float32)\n",
    "X_spo_snake = np.zeros((spo.shape[0], 256), dtype = np.float32)\n",
    "X_sys_snake = np.zeros((sys.shape[0], 256), dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_hr_snake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on audio 0\n"
     ]
    }
   ],
   "source": [
    "for i in range(dia.shape[0]):\n",
    "    b=dia[i]\n",
    "    k=0\n",
    "    print('on audio {}'.format(i))\n",
    "    for j in range(0,dia.shape[1],16):\n",
    "        if k%2==0:\n",
    "            X_dia_snake[i][j:j+16]=b[j:j+16]\n",
    "        else:\n",
    "            X_dia_snake[i][j:j+16]=np.flip(b[j:j+16],0)\n",
    "        k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on audio 0\n"
     ]
    }
   ],
   "source": [
    "for i in range(hr.shape[0]):\n",
    "    b=hr[i]\n",
    "    k=0\n",
    "    print('on audio {}'.format(i))\n",
    "    for j in range(0,hr.shape[1],16):\n",
    "        if k%2==0:\n",
    "            X_hr_snake[i][j:j+16]=b[j:j+16]\n",
    "        else:\n",
    "            X_hr_snake[i][j:j+16]=np.flip(b[j:j+16],0)\n",
    "        k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on audio 0\n"
     ]
    }
   ],
   "source": [
    "for i in range(rr.shape[0]):\n",
    "    b=rr[i]\n",
    "    k=0\n",
    "    print('on audio {}'.format(i))\n",
    "    for j in range(0,rr.shape[1],16):\n",
    "        if k%2==0:\n",
    "            X_rr_snake[i][j:j+16]=b[j:j+16]\n",
    "        else:\n",
    "            X_rr_snake[i][j:j+16]=np.flip(b[j:j+16],0)\n",
    "        k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on audio 0\n"
     ]
    }
   ],
   "source": [
    "for i in range(spo.shape[0]):\n",
    "    b=spo[i]\n",
    "    k=0\n",
    "    print('on audio {}'.format(i))\n",
    "    for j in range(0,spo.shape[1],16):\n",
    "        if k%2==0:\n",
    "            X_spo_snake[i][j:j+16]=b[j:j+16]\n",
    "        else:\n",
    "            X_spo_snake[i][j:j+16]=np.flip(b[j:j+16],0)\n",
    "        k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on audio 0\n"
     ]
    }
   ],
   "source": [
    "for i in range(sys.shape[0]):\n",
    "    b=sys[i]\n",
    "    k=0\n",
    "    print('on audio {}'.format(i))\n",
    "    for j in range(0,sys.shape[1],16):\n",
    "        if k%2==0:\n",
    "            X_sys_snake[i][j:j+16]=b[j:j+16]\n",
    "        else:\n",
    "            X_sys_snake[i][j:j+16]=np.flip(b[j:j+16],0)\n",
    "        k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[143.     , 142.3    , 145.6    , 144.9    , 141.9    , 146.4    ,\n",
       "        143.9    , 150.3    , 126.6    , 138.5    , 138.7    , 140.1    ,\n",
       "        146.6    , 145.5    , 147.8    , 148.1    , 144.5    , 143.1    ,\n",
       "        141.7    , 139.8    , 137.5    , 136.9    , 146.6    , 151.     ,\n",
       "        150.5    , 149.6    , 146.1    , 141.1    , 136.1    , 142.2    ,\n",
       "        144.1    , 137.2    , 144.2    , 146.3    , 142.2    , 142.8    ,\n",
       "        143.1    , 144.6    , 141.8    , 142.2    , 143.     , 141.4    ,\n",
       "        141.1    , 138.7    , 145.7    , 145.2    , 143.3    , 142.8    ,\n",
       "        138.4    , 134.8    , 138.2    , 139.4    , 138.     , 138.2    ,\n",
       "        135.5    , 141.     , 139.8    , 138.7    , 139.9    , 134.9    ,\n",
       "        139.9    , 137.8    , 138.8    , 138.2    , 142.8    , 141.3    ,\n",
       "        144.2    , 144.3    , 144.3    , 140.2    , 143.3    , 145.7    ,\n",
       "        144.8    , 144.8    , 148.     , 151.6    , 152.     , 152.5    ,\n",
       "        154.4    , 149.2    , 151.5    , 151.2    , 148.9    , 150.     ,\n",
       "        152.     , 146.6    , 145.8    , 146.9    , 150.9    , 149.4    ,\n",
       "        149.2    , 150.3    , 148.9    , 153.8    , 151.6    , 154.1    ,\n",
       "        150.9    , 150.8    , 153.8    , 151.4    , 155.5    , 154.3    ,\n",
       "        146.6    , 141.9    , 141.1    , 138.6    , 135.     , 115.8    ,\n",
       "        134.2    , 138.1    , 140.6    , 142.2    , 145.3    , 146.2    ,\n",
       "        141.5    , 140.4    , 142.6    , 126.2    , 145.3    , 144.3    ,\n",
       "        140.8    , 144.6    , 143.7    , 140.3    , 141.2    , 141.3    ,\n",
       "        143.8    , 141.1    , 136.1    , 141.9    , 135.6    , 139.9    ,\n",
       "        141.4    , 145.2    , 142.8    , 141.7    , 138.8    , 143.8    ,\n",
       "        140.3    , 142.9    , 140.     , 143.5    , 146.4    , 142.1    ,\n",
       "        139.6    , 135.5    , 144.6    , 137.2    , 143.3    , 139.2    ,\n",
       "        138.2    , 139.2    , 138.7    , 140.9    , 136.7    , 141.7    ,\n",
       "        139.5    , 138.5    , 135.4    , 144.     , 134.9    , 134.8    ,\n",
       "        138.5    , 134.1    , 135.9    , 133.     , 139.9    , 136.8    ,\n",
       "        137.6    , 141.5    , 138.6    , 142.4    , 141.1    , 141.8    ,\n",
       "        138.7    , 129.5    , 133.5    , 131.9    , 125.1    , 127.4    ,\n",
       "        124.6    , 130.48553, 127.     , 136.9    , 136.7    , 133.7    ,\n",
       "        135.9    , 133.9    , 135.     , 135.8    , 137.3    , 137.9    ,\n",
       "        129.5    , 131.2    , 129.2    , 136.7    , 134.5    , 128.7    ,\n",
       "        128.1    , 123.9    , 125.6    , 128.5    , 129.2    , 134.8    ,\n",
       "        133.7    , 139.4    , 131.4    , 138.9    , 131.5    , 130.1    ,\n",
       "        128.2    , 126.2    , 122.3    , 127.6    , 123.8    , 126.6    ,\n",
       "        123.5    , 125.1    , 126.9    , 132.6    , 128.9    , 132.3    ,\n",
       "        134.9    , 133.7    , 132.9    , 133.8    , 135.6    , 134.2    ,\n",
       "        132.7    , 128.8    , 125.1    , 122.4    , 116.8    , 129.15703,\n",
       "        129.00308, 169.6    , 120.7    , 118.6    , 120.5    , 121.1    ,\n",
       "        108.9    , 114.4    , 104.2    , 113.9    , 123.     , 121.5    ,\n",
       "        126.6    , 128.2    , 123.8    , 126.5    , 115.5    , 121.     ,\n",
       "        122.4    , 121.7    , 121.7    , 118.9    ]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sys_snake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Densenet Model prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.dstack([X_dia_snake, X_hr_snake, X_rr_snake, X_spo_snake, X_sys_snake])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(-1,16,16,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 54.8,  80. ,  16.1,  96. , 143. ],\n",
       "         [ 54.1,  80. ,   7.5,  95.8, 142.3],\n",
       "         [ 55.9,  80. ,  13.3,  96. , 145.6],\n",
       "         ...,\n",
       "         [ 56.6,  80. ,  18.6,  96. , 145.5],\n",
       "         [ 57.7,  80. ,  18.6,  96. , 147.8],\n",
       "         [ 57.9,  80. ,  17.5,  96. , 148.1]],\n",
       "\n",
       "        [[ 55.2,  80. ,  17.8,  96. , 144.5],\n",
       "         [ 54.7,  80. ,  17.5,  96. , 143.1],\n",
       "         [ 54.7,  80. ,  17.9,  96. , 141.7],\n",
       "         ...,\n",
       "         [ 54.7,  80. ,  16.5,  96.1, 142.2],\n",
       "         [ 55.6,  80. ,  17. ,  96.4, 144.1],\n",
       "         [ 53.9,  80. ,  16.8,  95.5, 137.2]],\n",
       "\n",
       "        [[ 55.2,  80. ,  19.1,  96. , 144.2],\n",
       "         [ 55.6,  80. ,  18.3,  96. , 146.3],\n",
       "         [ 55.1,  80. ,  20.6,  95.9, 142.2],\n",
       "         ...,\n",
       "         [ 55.1,  80. ,  16.5,  96. , 145.2],\n",
       "         [ 54.4,  80. ,  17.2,  96. , 143.3],\n",
       "         [ 54.1,  80. ,  16.2,  96. , 142.8]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 50.2,  80. ,  12.9,  97. , 131.5],\n",
       "         [ 49.8,  80. ,  13.1,  97. , 130.1],\n",
       "         [ 48.8,  80. ,  15.8,  96.4, 128.2],\n",
       "         ...,\n",
       "         [ 50. ,  80. ,  16.4,  97. , 132.3],\n",
       "         [ 51. ,  80. ,  14.2,  97. , 134.9],\n",
       "         [ 50.6,  80. ,  14. ,  97. , 133.7]],\n",
       "\n",
       "        [[ 50.7,  80. ,  14.1,  97. , 132.9],\n",
       "         [ 51. ,  80. ,  14.4,  97. , 133.8],\n",
       "         [ 51.1,  80. ,  14.3,  97. , 135.6],\n",
       "         ...,\n",
       "         [ 46.2,  81. ,  14.6,  95.6, 118.6],\n",
       "         [ 46. ,  80. ,  17. ,  95.6, 120.5],\n",
       "         [ 46.4,  80. ,  18.4,  96. , 121.1]],\n",
       "\n",
       "        [[ 43.2,  80. ,  16.1,  96. , 108.9],\n",
       "         [ 44.8,  80. ,  13.4,  95.4, 114.4],\n",
       "         [ 41.2,  80. ,  16.9,  95. , 104.2],\n",
       "         ...,\n",
       "         [ 46.4,  80. ,  16.6,  96.3, 121.7],\n",
       "         [ 47. ,  80. ,  14.3,  96. , 121.7],\n",
       "         [ 46.1,  80. ,  15.8,  96. , 118.9]]]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'scipy.misc' has no attribute 'imresize'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-0547bd4acab6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0marray_resized_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m320\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m240\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nearest'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'scipy.misc' has no attribute 'imresize'"
     ]
    }
   ],
   "source": [
    "array_resized_image = scipy.misc.imresize(X, (320, 240), interp='nearest', mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Too many dimensions: 4 > 3.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-7b21d9d06c9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/tav_lab/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2659\u001b[0m         \u001b[0mndmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mndmax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2661\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Too many dimensions: %d > %d.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m     \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Too many dimensions: 4 > 3."
     ]
    }
   ],
   "source": [
    "image = Image.fromarray(X, 'RGB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "dppABKl8tjqU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 30, 30, 5)\n"
     ]
    }
   ],
   "source": [
    "X = np.pad(X, ((0,0), (7,7), (7,7), (0,0)), mode='constant')\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]]], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 30\n",
    "img_width = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_calc1 = np.load('mean_shock_image_mimic.npy')\n",
    "std_calc1 = np.load('std_shock_image_mimic.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "X -= mean_calc1\n",
    "# Apply featurewise_std_normalization to test-data with statistics from train data\n",
    "X /= (std_calc1 + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import backend\n",
    "\n",
    "def dense_block(x, blocks, name):\n",
    "    \"\"\"A dense block.\n",
    "    # Arguments\n",
    "        x: input tensor.\n",
    "        blocks: integer, the number of building blocks.\n",
    "        name: string, block label.\n",
    "    # Returns\n",
    "        output tensor for the block.\n",
    "    \"\"\"\n",
    "    for i in range(blocks):\n",
    "        x = conv_block(x, 32, name=name + '_block' + str(i + 1))\n",
    "    return x\n",
    "\n",
    "\n",
    "def transition_block(x, reduction, name):\n",
    "    \"\"\"A transition block.\n",
    "    # Arguments\n",
    "        x: input tensor.\n",
    "        reduction: float, compression rate at transition layers.\n",
    "        name: string, block label.\n",
    "    # Returns\n",
    "        output tensor for the block.\n",
    "    \"\"\"\n",
    "    bn_axis = 3 if backend.image_data_format() == 'channels_last' else 1\n",
    "    x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n",
    "                                  name=name + '_bn')(x)\n",
    "    x = layers.Activation('relu', name=name + '_relu')(x)\n",
    "    x = layers.Conv2D(int(backend.int_shape(x)[bn_axis] * reduction), 1,\n",
    "                      use_bias=False,\n",
    "                      name=name + '_conv')(x)\n",
    "    x = layers.AveragePooling2D(2, strides=2, name=name + '_pool')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_block(x, growth_rate, name):\n",
    "    \"\"\"A building block for a dense block.\n",
    "    # Arguments\n",
    "        x: input tensor.\n",
    "        growth_rate: float, growth rate at dense layers.\n",
    "        name: string, block label.\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    \"\"\"\n",
    "    bn_axis = 3 if backend.image_data_format() == 'channels_last' else 1\n",
    "    x1 = layers.BatchNormalization(axis=bn_axis,\n",
    "                                   epsilon=1.001e-5,\n",
    "                                   name=name + '_0_bn')(x)\n",
    "    x1 = layers.Activation('relu', name=name + '_0_relu')(x1)\n",
    "    x1 = layers.Conv2D(4 * growth_rate, 1,\n",
    "                       use_bias=False,\n",
    "                       name=name + '_1_conv')(x1)\n",
    "    x1 = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n",
    "                                   name=name + '_1_bn')(x1)\n",
    "    x1 = layers.Activation('relu', name=name + '_1_relu')(x1)\n",
    "    x1 = layers.Conv2D(growth_rate, 3,\n",
    "                       padding='same',\n",
    "                       use_bias=False,\n",
    "                       name=name + '_2_conv')(x1)\n",
    "    x = layers.Concatenate(axis=bn_axis, name=name + '_concat')([x, x1])\n",
    "    return x\n",
    "\n",
    "def DenseNet(blocks=[6, 12, 24, 16]):\n",
    "    \n",
    "    input_shape = [img_height, img_width, 5]\n",
    "    img_input = layers.Input(shape=input_shape)\n",
    "    \n",
    "    bn_axis = 3 if backend.image_data_format() == 'channels_last' else 1\n",
    "\n",
    "    x = layers.ZeroPadding2D(padding=((3, 3), (3, 3)))(img_input)\n",
    "    x = layers.Conv2D(64, 7, strides=2, use_bias=False, name='conv1/conv')(x)\n",
    "    x = layers.BatchNormalization(\n",
    "        axis=bn_axis, epsilon=1.001e-5, name='conv1/bn')(x)\n",
    "    x = layers.Activation('relu', name='conv1/relu')(x)\n",
    "    x = layers.ZeroPadding2D(padding=((1, 1), (1, 1)))(x)\n",
    "    x = layers.MaxPooling2D(3, strides=2, name='pool1')(x)\n",
    "\n",
    "    x = dense_block(x, blocks[0], name='conv2')\n",
    "    x = transition_block(x, 0.5, name='pool2')\n",
    "    x = dense_block(x, blocks[1], name='conv3')\n",
    "    x = transition_block(x, 0.5, name='pool3')\n",
    "    x = dense_block(x, blocks[2], name='conv4')\n",
    "    x = transition_block(x, 0.5, name='pool4')\n",
    "    x = dense_block(x, blocks[3], name='conv5')\n",
    "\n",
    "    x = layers.BatchNormalization(\n",
    "        axis=bn_axis, epsilon=1.001e-5, name='bn')(x)\n",
    "    x = layers.Activation('relu', name='relu')(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "    x = layers.Dense(1, activation='sigmoid', name='fc')(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    inputs = img_input\n",
    "    model = models.Model(inputs, x, name='densenet121')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DenseNet()\n",
    "adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "model.load_weights('/Users/prakritiailavadi/Desktop/post_grad/project2/shock App/weights-snake-loop-model_0.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41117668"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'densenet.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: tensorflow_gpu-1.5.0-cp35-cp35m-win_amd64.whl is not a supported wheel on this platform.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/windows/gpu/tensorflow_gpu-1.5.0-cp35-cp35m-win_amd64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
